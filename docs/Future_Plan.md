# 方案迭代路线图
## 4.1 阶段 1：MVP（0-1 个月）
目标：验证核心价值，跑通基础流程
实施内容：

完成 5-10 道题的题库建设
实现 Step 1-5 的前端交互
实现规则引擎 + LLM 实时诊断
上线基础错题记录功能

成功指标：

学生能完整走完复盘流程
诊断结果对学生有实际帮助（通过用户访谈验证）
系统稳定运行

不做的事：

错误画像统计页面
预生成诊断模板
个性化推荐练习


## 4.2 阶段 2：性能优化（1-3 个月）
触发条件：

用户量增长到 100+ DAU
API 成本开始显著
学生抱怨等待时间过长

实施内容：
引入混合生成方案
核心思路：

结构化路径预生成模板 + 个性化内容实时生成

具体做法：

分析真实错误路径分布

统计哪些 Step 1-4 组合最常见
识别高频路径（占比 > 5%）


为高频路径预生成诊断模板

模板包含：

主要问题描述
解释框架（带占位符）
改进建议


每个路径生成 1 个版本
预生成成本：约 $1-2（500 次 LLM 调用）


实时生成仅用于两种情况：

低频路径（占比 < 5%）
学生有自由输入内容时



预期效果：

70-80% 的请求无需调用 LLM
响应时间从 3 秒降至 < 500ms
API 成本降低 70%
诊断质量可控（预生成内容经人工审核）


建立质量监控体系
用户反馈机制：
诊断结果页底部：
"这个诊断对你有帮助吗？"
👍 有帮助   👎 没帮助

如果 👎，可选填写：
[简短反馈框]
质量迭代流程：

收集每个模板的反馈数据
针对差评率 > 30% 的模板进行优化
生成 2-3 个新版本
小范围 A/B 测试
选出最优版本替换

为什么不在 MVP 就做 A/B 测试：

增加学生评价负担（体验疲劳）
MVP 用户量不够，统计意义不足
先快速上线，后优化更高效


## 4.3 阶段 3：个性化增强（3-6 个月）
触发条件：

题库扩展到 50+ 题
用户量 > 1000 DAU
积累了大量学生错误数据

实施内容：
引入学生错误画像
错误画像维度：
维度 1：错误步骤分布
- 定位失误：35%
- 理解偏差：50%  ← 主要问题
- 选项分析：15%

维度 2：题型错误分布
- 事实信息题：错误率 20%
- 推断题：错误率 45%  ← 主要问题
- 修辞目的题：错误率 35%

维度 3：语言层面问题
- 长难句理解困难
- 熟词僻义误判频繁
- 指代关系混淆
画像应用场景：

LLM 诊断时加入历史错误上下文

  "你在推断题上频繁出现过度推断的问题，
  这次也是类似情况..."

个性化推荐练习题

  "根据你的错误画像，建议重点练习：
  - 推断题（因果推理类）
  - 长难句分析专项"

完善预生成模板库
全量预生成策略：

为所有题目的所有逻辑路径预生成模板
建立模板版本管理系统
持续优化低评分模板

模板个性化填充：

基础内容：从预生成模板加载
个性化内容：实时 LLM 生成

学生自由输入分析
结合错误画像的针对性建议




## 4.4 阶段 4：智能闭环（6+ 个月）
愿景：从"错题诊断"到"学习闭环"
扩展方向：
1. Agent-based 题目生成

基于修改后的托福文本自动生成模拟题
控制题型、难度与语言特征
针对学生薄弱环节生成针对性练习

2. 多模态复盘

不仅是"选择 + 输入"
引入"拼装式理解"（类多邻国）

给出关键词/短语
学生组装成完整理解
系统判断逻辑是否正确


语音解释（学生口述解题思路）

3. 教师端 Dashboard

班级错误画像聚合
识别共性问题
自动生成教学建议



# 未来功能迭代 TODO List

## 阶段 1：性能与质量优化（1-3 个月后）

### 错误类型细化分析（研究型）
- **功能**：对"答案句理解偏差"进行更细粒度的自动归因
- **实施方式**：
  - 方式 1：基于 LLM 的自动分类
    - 输入：答案句 + 学生理解 + 正确理解
    - 输出：偏差类型标签（因果/转折/限定/指代...）
  - 方式 2：基于规则的语言学分析
    - 识别答案句中的关键逻辑词（through, however, only...）
    - 对比学生理解是否覆盖这些逻辑点
- **价值**：
  - 学术研究：发表关于托福阅读认知过程的论文
  - 教学改进：更精准的知识点推荐
- **前置条件**：
  - 积累至少 500+ 条复盘数据
  - 人工标注部分数据作为训练集

### 1.1 混合生成方案

功能：引入预生成诊断模板 + 实时个性化补充
在 MVP 基础上增加：

新增数据表：diagnosis_templates（存储预生成的诊断模板）
模板匹配引擎（根据 Step 1-5 选择匹配预生成模板）


修改：

LLM 调用逻辑改为"仅在有自由输入或低频路径时调用"


目的：

响应速度从 3 秒降至 < 500ms
API 成本降低 70%
诊断质量可控（预生成内容经人工审核）


### 1.2 质量监控与迭代

功能：建立诊断反馈机制 + A/B 测试系统
在 MVP 基础上增加：

诊断结果页底部增加"👍 有帮助 / 👎 没帮助"按钮
新增数据表：diagnosis_feedback（记录用户反馈）
后台 Dashboard：统计各模板的好评率


修改：

针对差评率 > 30% 的模板生成 2-3 个新版本进行 A/B 测试


目的：

持续优化诊断质量
用数据驱动模板迭代


### 1.3 知识点自适应展示

功能：根据学生掌握情况动态隐藏知识点提示
在 MVP 基础上增加：

追踪学生在每个步骤的历史正确率
规则：某步骤连续正确 5 次 OR 总正确率 > 90% → 隐藏该步骤的知识点提示


修改：

前端在渲染知识点时查询学生掌握度


目的：

减少对熟练学生的干扰
提升复盘效率


## 阶段 2：个性化增强（3-6 个月后）

### 2.1 学生错误画像系统

功能：多维度分析学生错误模式
在 MVP 基础上增加：

新增模块：错误画像统计引擎
画像维度：

错误步骤分布（定位 vs 理解 vs 选项分析）
题型错误分布（事实信息题 vs 推断题 vs 修辞目的题）
语言层面问题（长难句 vs 词汇 vs 逻辑关系）


新增页面：个人错误画像 Dashboard


修改：

LLM 诊断时加入学生历史错误画像作为上下文


目的：

诊断更具针对性："你在推断题上频繁出现过度推断..."
为个性化推荐练习提供依据


### 2.2 个性化练习推荐

功能：根据错误画像推荐针对性练习
在 MVP 基础上增加：

推荐引擎：分析学生薄弱环节 → 筛选题库中的相关题目
推荐页面："根据你的错误画像，建议重点练习..."


目的：

从"诊断"到"改进"形成闭环
提升学习效率


### 2.3 错误类型细化分析

功能：对"答案句理解偏差"进行更细粒度的归因
在 MVP 基础上增加：

细分类型：

因果关系误判
转折逻辑遗漏
限定条件忽略
指代关系混淆


通过 LLM 或规则引擎自动识别具体偏差类型


修改：

规则引擎增加子分类判断逻辑
错误画像增加细粒度统计


目的：

更精确地识别学生的认知弱点
为教学干预提供更具体的方向


## 阶段 3：智能化升级（6+ 个月后）

### 3.1 拼装式理解（类多邻国）

功能：通过词汇/短语组装检验学生理解
在 MVP 基础上增加：

为每道题设计拼装素材库（关键词 + 干扰词）
新交互组件：拖拽/点选组装界面
判断算法：验证学生组装的逻辑正确性


修改：

Step 3（答案句理解）增加"拼装模式"选项
或作为独立的"练习模式"（区别于"诊断模式"）


目的：

提升交互趣味性
更深入检验学生对逻辑关系的理解


### 3.2 Agent-based 题目生成

功能：基于学生薄弱环节自动生成练习题
在 MVP 基础上增加：

题目生成 Agent：

输入：学生错误画像 + 托福文本库
输出：针对性模拟题（控制题型、难度、考点）


质量审核机制（人工或 LLM 双重验证）


目的：

解决题库扩展瓶颈
实现真正的"千人千面"练习


### 3.3 多模态复盘

功能：支持语音解释、视觉标注等多种复盘方式
在 MVP 基础上增加：

语音输入：学生口述解题思路 → 语音转文字 → LLM 分析
视觉标注：学生在文章中直接划线/高亮定位词和答案句


目的：

降低文字输入负担
更自然地捕捉学生思维过程


### 3.4 教师端 Dashboard

功能：班级错误画像聚合 + 教学建议生成
在 MVP 基础上增加：

新角色权限：教师账户
新页面：

班级整体错误分布
个体学生对比分析
共性问题识别


LLM 生成教学建议："本班在推断题上普遍存在..."


目的：

辅助教师精准教学
提升产品 B 端价值


## 阶段 4：研究型扩展（1 年+ 后）
### 4.1 错误路径建模（Error Trajectory Modeling）

功能：建模学生从错误到改进的完整路径
在 MVP 基础上增加：

追踪学生在相同题型/考点上的多次表现
机器学习模型：预测学生未来易错点


目的：

学术研究价值（可发表论文）
实现"预防性"教学干预


### 4.2 多语言支持

功能：支持全英文或其他语言的复盘流程
在 MVP 基础上增加：

国际化（i18n）框架
多语言 LLM prompt 设计


目的：

扩展国际用户
探索跨语言学习规律


## 技术债务与工程优化（持续进行）

### 优化 1：数据库性能优化

时机：用户量 > 1000 DAU 或题库 > 100 题
内容：

增加索引（question_id, user_id, created_at）
考虑引入缓存（Redis）
分表策略（按时间或用户分片）


### 优化 2：前端性能优化

时机：页面加载时间 > 2 秒
内容：

懒加载（题目文本、选项）
预加载下一题资源
优化图片/静态资源


### 优化 3：LLM 调用优化

时机：API 成本占比 > 20%
内容：

Prompt 压缩（减少 token 消耗）
尝试更便宜的模型（如 Claude Haiku）
批量调用优化